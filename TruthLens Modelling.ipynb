{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0099a3df",
   "metadata": {},
   "source": [
    "# TruthLens Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bbafe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3575d2",
   "metadata": {},
   "source": [
    "## Phase 1: Binary Classification\n",
    "\n",
    "### Feature Extraction Using TF-IDF and n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0294bbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "df = pd.read_csv('Data/final_clean.csv')\n",
    "df = df.dropna(subset=['content'])\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82c2d09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction: 166.8379 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 3))\n",
    "X = vectorizer.fit_transform(df['content'])\n",
    "y = df['label']\n",
    "print(\"Feature extraction: {:.4f} seconds\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b78885",
   "metadata": {},
   "source": [
    "### Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9e43640",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retain the indices as we need these for looking up explanations later\n",
    "train_indices, test_indices = train_test_split(df.index, test_size=0.2, random_state=42)\n",
    "# Split X and y using the train/test indices\n",
    "X_train = X[train_indices]\n",
    "X_test = X[test_indices]\n",
    "y_train = y.iloc[train_indices]\n",
    "y_test = y.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e070dd26",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78b9b216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit Logistic Regression model: 1.7987 seconds\n",
      "Accuracy: 0.9901960784313726\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      4288\n",
      "           1       0.99      0.99      0.99      4688\n",
      "\n",
      "    accuracy                           0.99      8976\n",
      "   macro avg       0.99      0.99      0.99      8976\n",
      "weighted avg       0.99      0.99      0.99      8976\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Fit Logistic Regression model: {:.4f} seconds\".format(time.time() - start_time))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456ca6c5",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc05b267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit SVM model: 1474.6836 seconds\n",
      "SVM Accuracy: 0.9954322638146168\n",
      "SVM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4288\n",
      "           1       1.00      0.99      1.00      4688\n",
      "\n",
      "    accuracy                           1.00      8976\n",
      "   macro avg       1.00      1.00      1.00      8976\n",
      "weighted avg       1.00      1.00      1.00      8976\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train SVM\n",
    "start_time = time.time()\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_pred = svm_model.predict(X_test)\n",
    "print(\"Fit SVM model: {:.4f} seconds\".format(time.time() - start_time))\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_pred))\n",
    "print(\"SVM Classification Report:\\n\", classification_report(y_test, svm_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9278c3c3",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2e81fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit Random Forest model: 141.1706 seconds\n",
      "Random Forest Accuracy: 0.9953208556149733\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4288\n",
      "           1       1.00      0.99      1.00      4688\n",
      "\n",
      "    accuracy                           1.00      8976\n",
      "   macro avg       1.00      1.00      1.00      8976\n",
      "weighted avg       1.00      1.00      1.00      8976\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "print(\"Fit Random Forest model: {:.4f} seconds\".format(time.time() - start_time))\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, rf_pred))\n",
    "print(\"Random Forest Classification Report:\\n\", classification_report(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53942a27",
   "metadata": {},
   "source": [
    "### Explain prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65d749ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_prediction(text):\n",
    "    \"\"\"\n",
    "    Explains the prediction of the model by showing the most influential words for the prediction.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    text : str\n",
    "        The input text to analyze.\n",
    "    model : object\n",
    "        The trained machine learning model.\n",
    "    vectorizer : object\n",
    "        The TF-IDF vectorizer used to transform the text.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary containing the prediction ('label') and the top contributing words ('features').\n",
    "    \"\"\"\n",
    "    # Transform the text using the vectorizer\n",
    "    tfidf_text = vectorizer.transform([text])\n",
    "    # Predict the label\n",
    "    prediction = model.predict(tfidf_text)[0]\n",
    "    # Get top contributing features (words)\n",
    "    feature_importances = model.coef_[0]  # Logistic regression coefficients\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    # Sort by importance\n",
    "    top_indices = tfidf_text.toarray().argsort()[0][-5:]  # Top 5 features\n",
    "    top_features = [feature_names[i] for i in top_indices]\n",
    "\n",
    "    return {\n",
    "        \"label\": prediction,\n",
    "        \"features\": top_features\n",
    "    }\n",
    "\n",
    "# Create a DataFrame for test data\n",
    "test_df = pd.DataFrame({\n",
    "    'text': df.loc[test_indices, 'content'].reset_index(drop=True),\n",
    "    'true_label': y_test.reset_index(drop=True),\n",
    "    'predicted_label': y_pred\n",
    "})\n",
    "\n",
    "# Row predicted as Real (0)\n",
    "real_example = test_df[test_df['predicted_label'] == 0].iloc[0]\n",
    "\n",
    "# Row predicted as Fake (1)\n",
    "fake_example = test_df[test_df['predicted_label'] == 1].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bc090e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Example Prediction:\n",
      "Text: china say resolutely opposes deployment thaad south korea beijing china say friday resolutely oppose deployment u.s. anti-missile defense system south korea south korea say defense chief agree deploy system year chinese foreign ministry spokesman lu kang reiterate china 's opposition u.s. system daily news briefing beijing china consistently oppose decision deploy terminal high altitude area defense system say threaten china 's security nothing ease tension korean peninsula south korea united states say system intend defend north korean aggression\n",
      "Predicted Label: 0\n",
      "Top Features: ['south', 'korea', 'system', 'china', 'south korea']\n",
      "\n",
      "Fake Example Prediction:\n",
      "Text: anti-abortion republican cheated tried get mistress abortion text message send january u.s. rep. tim murphy staunch pro-life republican represent pennsylvania 18th district reveal text woman murphy relationship outside marriage take task anti-abortion statement post facebook office public account pittsburg post-gazette report zero issue post pro-life stance place issue ask abort unborn child last week think one option write shannon edwards forensic psychologist pittsburgh congressman admit last month extramarital relationship mrs. edwards go divorce follow affair.murphy publicly admit affair last month last year become involve affair personal friend nobody fault offer excuse extent blame matter fall solely upon say statement time.the gazette note text paper obtain murphy cell phone number day respond say get say march life message never write staff read wince continue tell staff write never believe anti-choice message touted.the gazette report congressman laud family research council stance abortion well family value generally also endorse lifepac oppose abortion right member house pro-life caucus affiliation often cite office.in addition murphy problem six-page memo pennsylvania republican presumably write chief staff susan mosychuk describe hostile workplace murphy repeatedly denigrate employee threaten create state terror apparently pro-life republican mean respect life secretly opt pro-choice murphy vote funding planned parenthood vote federal funding research utilize human embryonic stem cell consistently vote pro-choice proposals.image via screen capture\n",
      "Predicted Label: 1\n",
      "Top Features: ['text', 'life', 'pro', 'abortion', 'murphy']\n"
     ]
    }
   ],
   "source": [
    "real_explanation = explain_prediction(real_example['text'])\n",
    "fake_explanation = explain_prediction(fake_example['text'])\n",
    "\n",
    "print(\"Real Example Prediction:\")\n",
    "print(\"Text:\", real_example['text'])\n",
    "print(\"Predicted Label:\", real_explanation['label'])\n",
    "print(\"Top Features:\", real_explanation['features'])\n",
    "\n",
    "print(\"\\nFake Example Prediction:\")\n",
    "print(\"Text:\", fake_example['text'])\n",
    "print(\"Predicted Label:\", fake_explanation['label'])\n",
    "print(\"Top Features:\", fake_explanation['features'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a6c761",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
