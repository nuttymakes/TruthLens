{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1456b888",
   "metadata": {},
   "source": [
    "# TruthLens Modelling - Phase 2: Multi-class Classification\n",
    "The aim of phase 2 is to further classify text which has already been flagged as \"fake\" into one of four different types of fake news. These four classes - Fabricated, Polarised, Satire and Commentary - are a reduced adaption of the Molina et al. Disinformation Taxonomy. \n",
    "\n",
    "The dataset used is this phase is the custom dataset I created, which has already been cleaned and preprocessed (see \"TruthLens Data Collection\" and \"TruthLens Data Cleaning\" notebooks).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aee53cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#required imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from textblob import TextBlob\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_predict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "import time\n",
    "#from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.keras.layers import Dense, Dropout\n",
    "#from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "#set a seed value for reproducability\n",
    "np.random.seed(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5fed05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     --------------------------------------- 12.8/12.8 MB 10.2 MB/s eta 0:00:00\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "#spaCy's small English model download\n",
    "!python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5b6c7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             content  label  word_count  \\\n",
      "0  Perdue Announces Initiative To Even The Playin...      2         207   \n",
      "1  Met Police just BLOCKED a pro-Palestine protes...      1         591   \n",
      "2  Here's the moment Mark Zuckerberg gave away th...      1         515   \n",
      "\n",
      "   sentence_count  flesch_reading_ease  \\\n",
      "0               8                45.19   \n",
      "1              22                35.91   \n",
      "2              25                50.67   \n",
      "\n",
      "                                       content_lemma  \\\n",
      "0  Perdue Announces Initiative To Even The Playin...   \n",
      "1  Met Police just BLOCKED a pro-Palestine protes...   \n",
      "2  Here 's the moment Mark Zuckerberg give away t...   \n",
      "\n",
      "                                content_lemma_nostop  \n",
      "0  perdue announces initiative even playing field...  \n",
      "1  met police blocked propalestine protest march ...  \n",
      "2  moment mark zuckerberg give away game like res...  \n",
      "--------------------------------------------------\n",
      "Class distribution:\n",
      "2    400\n",
      "1    400\n",
      "3    400\n",
      "0    400\n",
      "Name: label, dtype: int64 \n",
      "\n",
      "--------------------------------------------------\n",
      "Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600 entries, 0 to 1599\n",
      "Data columns (total 7 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   content               1600 non-null   object \n",
      " 1   label                 1600 non-null   int64  \n",
      " 2   word_count            1600 non-null   int64  \n",
      " 3   sentence_count        1600 non-null   int64  \n",
      " 4   flesch_reading_ease   1600 non-null   float64\n",
      " 5   content_lemma         1600 non-null   object \n",
      " 6   content_lemma_nostop  1600 non-null   object \n",
      "dtypes: float64(1), int64(3), object(3)\n",
      "memory usage: 87.6+ KB\n",
      "None \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "df = pd.read_csv('Data/phase2_final_clean.csv')\n",
    "df = df.reset_index(drop=True)\n",
    "print(df.head(3))\n",
    "print(\"-\" * 50)\n",
    "print(\"Class distribution:\")\n",
    "print(df['label'].value_counts(), \"\\n\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Dataset Information:\")\n",
    "print(df.info(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7db2d491",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['content_lemma']\n",
    "y = df['label']\n",
    "\n",
    "#Stratified train-test split helps maintain class balance\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5664bd82",
   "metadata": {},
   "source": [
    "### Generate baseline\n",
    "We will generate a simple baseline using Logistic Regression and TF-IDF features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c568bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1 Score: 0.859264381466872\n",
      "\n",
      "Classification Report for Logistic Regression:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.86      0.80       320\n",
      "           1       0.83      0.73      0.77       320\n",
      "           2       0.92      0.87      0.89       320\n",
      "           3       0.96      0.98      0.97       320\n",
      "\n",
      "    accuracy                           0.86      1280\n",
      "   macro avg       0.86      0.86      0.86      1280\n",
      "weighted avg       0.86      0.86      0.86      1280\n",
      "\n",
      "Run time: 6.6077 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#pipeline - creates TF-IDF features then creates the logistic regression model\n",
    "baseline_pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(max_features=5000)),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "#stratified k-fold cross-validation - this ensures each fold has a similar class distribution\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "#generate predictions\n",
    "predicted_labels = cross_val_predict(baseline_pipeline, X_train, y_train, cv=skf, method=\"predict\")\n",
    "\n",
    "#calculate f1 score\n",
    "f1_macro = f1_score(y_train, predicted_labels, average=\"macro\")\n",
    "print(\"Logistic Regression Macro F1 Score:\", f1_macro)\n",
    "\n",
    "#get classification report\n",
    "report = classification_report(y_train, predicted_labels)\n",
    "print(\"\\nClassification Report for Logistic Regression:\\n\", report)\n",
    "\n",
    "print(\"Run time: {:.4f} seconds\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b800541",
   "metadata": {},
   "source": [
    "### Choose best model\n",
    "Next we will test three different models to see which performs the best.\n",
    "\n",
    "#### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5e049da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Macro F1 Score: 0.6195257542552863\n",
      "\n",
      "Classification Report for Multinomial Naive Bayes:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.88      0.62       320\n",
      "           1       0.61      0.59      0.60       320\n",
      "           2       0.82      0.64      0.72       320\n",
      "           3       1.00      0.37      0.54       320\n",
      "\n",
      "    accuracy                           0.62      1280\n",
      "   macro avg       0.73      0.62      0.62      1280\n",
      "weighted avg       0.73      0.62      0.62      1280\n",
      "\n",
      "Run time: 4.1980 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "mnb_pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(max_features=5000)),\n",
    "    (\"clf\", MultinomialNB())\n",
    "])\n",
    "\n",
    "#generate predictions\n",
    "predicted_labels_mnb = cross_val_predict(mnb_pipeline, X_train, y_train, cv=skf, method=\"predict\")\n",
    "\n",
    "#print results\n",
    "f1_macro_mnb = f1_score(y_train, predicted_labels_mnb, average=\"macro\")\n",
    "print(\"Multinomial Naive Bayes Macro F1 Score:\", f1_macro_mnb)\n",
    "print(\"\\nClassification Report for Multinomial Naive Bayes:\\n\", classification_report(y_train, predicted_labels_mnb))\n",
    "\n",
    "print(\"Run time: {:.4f} seconds\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4375eb",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57660239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Macro F1 Score: 0.8723158805931359\n",
      "\n",
      "Classification Report for XGBoost:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82       320\n",
      "           1       0.82      0.75      0.78       320\n",
      "           2       0.89      0.91      0.90       320\n",
      "           3       0.99      0.98      0.99       320\n",
      "\n",
      "    accuracy                           0.87      1280\n",
      "   macro avg       0.87      0.87      0.87      1280\n",
      "weighted avg       0.87      0.87      0.87      1280\n",
      "\n",
      "Run time: 137.5719 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "xgb_pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(max_features=5000)),\n",
    "    (\"clf\", XGBClassifier(eval_metric='mlogloss', random_state=42))\n",
    "])\n",
    "\n",
    "#generate predictions\n",
    "predicted_labels_xgb = cross_val_predict(xgb_pipeline, X_train, y_train, cv=skf, method=\"predict\")\n",
    "\n",
    "#print results\n",
    "f1_macro_xgb = f1_score(y_train, predicted_labels_xgb, average=\"macro\")\n",
    "print(\"XGBoost Macro F1 Score:\", f1_macro_xgb)\n",
    "print(\"\\nClassification Report for XGBoost:\\n\", classification_report(y_train, predicted_labels_xgb))\n",
    "\n",
    "print(\"Run time: {:.4f} seconds\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bec846b",
   "metadata": {},
   "source": [
    "#### Feed forward neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "881014ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KerasClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 22\u001b[0m\n\u001b[0;32m     16\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m     19\u001b[0m nn_pipeline \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[0;32m     20\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtfidf\u001b[39m\u001b[38;5;124m\"\u001b[39m, TfidfVectorizer(max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m)),\n\u001b[0;32m     21\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_dense\u001b[39m\u001b[38;5;124m\"\u001b[39m, DenseTransformer()),\n\u001b[1;32m---> 22\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mKerasClassifier\u001b[49m(build_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m: create_ffnn_model(\u001b[38;5;241m5000\u001b[39m),\n\u001b[0;32m     23\u001b[0m                               epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m     24\u001b[0m ])\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m#generate predictions\u001b[39;00m\n\u001b[0;32m     27\u001b[0m predicted_labels_nn \u001b[38;5;241m=\u001b[39m cross_val_predict(nn_pipeline, X_train, y_train, cv\u001b[38;5;241m=\u001b[39mskf, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'KerasClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "#transformer to convert a sparse matrix (TFIDF) to a dense array\n",
    "class DenseTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X.todense()\n",
    "\n",
    "#create the feed forward neural network\n",
    "def create_ffnn_model(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "nn_pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(max_features=5000)),\n",
    "    (\"to_dense\", DenseTransformer()),\n",
    "    (\"clf\", KerasClassifier(build_fn=lambda: create_ffnn_model(5000),\n",
    "                              epochs=5, batch_size=32, verbose=0))\n",
    "])\n",
    "\n",
    "#generate predictions\n",
    "predicted_labels_nn = cross_val_predict(nn_pipeline, X_train, y_train, cv=skf, method=\"predict\")\n",
    "\n",
    "#print results\n",
    "f1_macro_nn = f1_score(y_train, predicted_labels_nn, average=\"macro\")\n",
    "print(\"Feedforward Neural Network Macro F1 Score:\", f1_macro_nn)\n",
    "print(\"\\nClassification Report for Feedforward Neural Network:\\n\", classification_report(y_train, predicted_labels_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682273cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8ee932",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
