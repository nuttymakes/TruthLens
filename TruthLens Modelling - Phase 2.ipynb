{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1456b888",
      "metadata": {
        "id": "1456b888"
      },
      "source": [
        "# TruthLens Modelling - Phase 2: Multi-class Classification\n",
        "The aim of phase 2 is to further classify text which has already been flagged as \"fake\" into one of four different types of fake news. These four classes - Fabricated, Polarised, Satire and Commentary - are a reduced adaption of the Molina et al. Disinformation Taxonomy.\n",
        "\n",
        "The dataset used is this phase is the custom dataset I created, which has already been cleaned and preprocessed (see \"TruthLens Data Collection\" and \"TruthLens Data Cleaning\" notebooks).\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.12.0"
      ],
      "metadata": {
        "id": "-MvdLC_PkY4a"
      },
      "id": "-MvdLC_PkY4a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install joblib"
      ],
      "metadata": {
        "id": "bjrcCUpSoVtE",
        "outputId": "d79bb19b-f445-4f9d-aa79-96d71b6f4884",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "bjrcCUpSoVtE",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "aee53cf6",
      "metadata": {
        "id": "aee53cf6"
      },
      "outputs": [],
      "source": [
        "#required imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "from gensim.models.ldamodel import LdaModel\n",
        "from textblob import TextBlob\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_predict, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from xgboost import XGBClassifier\n",
        "import time\n",
        "from itertools import chain, combinations\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "import joblib\n",
        "\n",
        "#set a seed value for reproducability\n",
        "np.random.seed(999)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5fed05f",
      "metadata": {
        "id": "c5fed05f"
      },
      "outputs": [],
      "source": [
        "#spaCy's small English model download\n",
        "!python -m spacy download en_core_web_sm\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "c5b6c7ca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5b6c7ca",
        "outputId": "6e419f71-5876-432b-cf8e-6be6f3c25fbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             content  label  word_count  \\\n",
            "0  Perdue Announces Initiative To Even The Playin...      2         207   \n",
            "1  Met Police just BLOCKED a pro-Palestine protes...      1         591   \n",
            "2  Here's the moment Mark Zuckerberg gave away th...      1         515   \n",
            "\n",
            "   sentence_count  flesch_reading_ease  \\\n",
            "0               8                45.19   \n",
            "1              22                35.91   \n",
            "2              25                50.67   \n",
            "\n",
            "                                       content_lemma  \\\n",
            "0  Perdue Announces Initiative To Even The Playin...   \n",
            "1  Met Police just BLOCKED a pro-Palestine protes...   \n",
            "2  Here 's the moment Mark Zuckerberg give away t...   \n",
            "\n",
            "                                content_lemma_nostop  \n",
            "0  perdue announces initiative even playing field...  \n",
            "1  met police blocked propalestine protest march ...  \n",
            "2  moment mark zuckerberg give away game like res...  \n",
            "--------------------------------------------------\n",
            "Class distribution:\n",
            "label\n",
            "2    400\n",
            "1    400\n",
            "3    400\n",
            "0    400\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "--------------------------------------------------\n",
            "Dataset Information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1600 entries, 0 to 1599\n",
            "Data columns (total 7 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   content               1600 non-null   object \n",
            " 1   label                 1600 non-null   int64  \n",
            " 2   word_count            1600 non-null   int64  \n",
            " 3   sentence_count        1600 non-null   int64  \n",
            " 4   flesch_reading_ease   1600 non-null   float64\n",
            " 5   content_lemma         1600 non-null   object \n",
            " 6   content_lemma_nostop  1600 non-null   object \n",
            "dtypes: float64(1), int64(3), object(3)\n",
            "memory usage: 87.6+ KB\n",
            "None \n",
            "\n"
          ]
        }
      ],
      "source": [
        "#load data\n",
        "df = pd.read_csv('Data/phase2_final_clean.csv')\n",
        "df = df.reset_index(drop=True)\n",
        "print(df.head(3))\n",
        "print(\"-\" * 50)\n",
        "print(\"Class distribution:\")\n",
        "print(df['label'].value_counts(), \"\\n\")\n",
        "print(\"-\" * 50)\n",
        "print(\"Dataset Information:\")\n",
        "print(df.info(), \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "7db2d491",
      "metadata": {
        "id": "7db2d491"
      },
      "outputs": [],
      "source": [
        "X = df['content_lemma']\n",
        "y = df['label']\n",
        "\n",
        "#Stratified train-test split helps maintain class balance\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=999)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5664bd82",
      "metadata": {
        "id": "5664bd82"
      },
      "source": [
        "### Generate baseline\n",
        "We will generate a simple baseline using Logistic Regression and TF-IDF features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "9c568bb9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c568bb9",
        "outputId": "5f19611b-0701-4fc2-8f4a-27ecf96cba12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Macro F1 Score: 0.8677662531487172\n",
            "\n",
            "Classification Report for Logistic Regression:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.89      0.81       320\n",
            "           1       0.85      0.73      0.78       320\n",
            "           2       0.94      0.87      0.90       320\n",
            "           3       0.96      0.99      0.98       320\n",
            "\n",
            "    accuracy                           0.87      1280\n",
            "   macro avg       0.87      0.87      0.87      1280\n",
            "weighted avg       0.87      0.87      0.87      1280\n",
            "\n",
            "Run time: 6.9260 seconds\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "#pipeline - creates TF-IDF features then creates the logistic regression model\n",
        "baseline_pipeline = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer(max_features=5000)),\n",
        "    (\"clf\", LogisticRegression(max_iter=1000, random_state=999))\n",
        "])\n",
        "\n",
        "#stratified k-fold cross-validation - this ensures each fold has a similar class distribution\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=999)\n",
        "\n",
        "#generate predictions\n",
        "predicted_labels = cross_val_predict(baseline_pipeline, X_train, y_train, cv=skf, method=\"predict\")\n",
        "\n",
        "#calculate f1 score\n",
        "f1_macro = f1_score(y_train, predicted_labels, average=\"macro\")\n",
        "print(\"Logistic Regression Macro F1 Score:\", f1_macro)\n",
        "\n",
        "#get classification report\n",
        "report = classification_report(y_train, predicted_labels)\n",
        "print(\"\\nClassification Report for Logistic Regression:\\n\", report)\n",
        "\n",
        "print(\"Run time: {:.4f} seconds\".format(time.time() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b800541",
      "metadata": {
        "id": "6b800541"
      },
      "source": [
        "### Choose best model\n",
        "Next we will test three different models to see which performs the best.\n",
        "\n",
        "#### Multinomial Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "b5e049da",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5e049da",
        "outputId": "2ac3c2a2-72d7-42ad-f4bb-9768d0c0fe4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multinomial Naive Bayes Macro F1 Score: 0.6480536690632447\n",
            "\n",
            "Classification Report for Multinomial Naive Bayes:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.90      0.63       320\n",
            "           1       0.68      0.62      0.65       320\n",
            "           2       0.82      0.63      0.71       320\n",
            "           3       1.00      0.43      0.60       320\n",
            "\n",
            "    accuracy                           0.65      1280\n",
            "   macro avg       0.74      0.65      0.65      1280\n",
            "weighted avg       0.74      0.65      0.65      1280\n",
            "\n",
            "Run time: 2.8825 seconds\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "mnb_pipeline = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer(max_features=5000)),\n",
        "    (\"clf\", MultinomialNB())\n",
        "])\n",
        "\n",
        "#generate predictions\n",
        "predicted_labels_mnb = cross_val_predict(mnb_pipeline, X_train, y_train, cv=skf, method=\"predict\")\n",
        "\n",
        "#print results\n",
        "f1_macro_mnb = f1_score(y_train, predicted_labels_mnb, average=\"macro\")\n",
        "print(\"Multinomial Naive Bayes Macro F1 Score:\", f1_macro_mnb)\n",
        "print(\"\\nClassification Report for Multinomial Naive Bayes:\\n\", classification_report(y_train, predicted_labels_mnb))\n",
        "\n",
        "print(\"Run time: {:.4f} seconds\".format(time.time() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d4375eb",
      "metadata": {
        "id": "7d4375eb"
      },
      "source": [
        "#### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "57660239",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57660239",
        "outputId": "04d61d91-f554-412c-eeb1-aa3f45543cff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Macro F1 Score: 0.8695792933725124\n",
            "\n",
            "Classification Report for XGBoost:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.85      0.82       320\n",
            "           1       0.84      0.74      0.79       320\n",
            "           2       0.87      0.91      0.89       320\n",
            "           3       0.98      0.97      0.98       320\n",
            "\n",
            "    accuracy                           0.87      1280\n",
            "   macro avg       0.87      0.87      0.87      1280\n",
            "weighted avg       0.87      0.87      0.87      1280\n",
            "\n",
            "Run time: 131.4418 seconds\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "xgb_pipeline = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer(max_features=5000)),\n",
        "    (\"clf\", XGBClassifier(eval_metric='mlogloss', random_state=999))\n",
        "])\n",
        "\n",
        "#generate predictions\n",
        "predicted_labels_xgb = cross_val_predict(xgb_pipeline, X_train, y_train, cv=skf, method=\"predict\")\n",
        "\n",
        "#print results\n",
        "f1_macro_xgb = f1_score(y_train, predicted_labels_xgb, average=\"macro\")\n",
        "print(\"XGBoost Macro F1 Score:\", f1_macro_xgb)\n",
        "print(\"\\nClassification Report for XGBoost:\\n\", classification_report(y_train, predicted_labels_xgb))\n",
        "\n",
        "print(\"Run time: {:.4f} seconds\".format(time.time() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bec846b",
      "metadata": {
        "id": "5bec846b"
      },
      "source": [
        "#### Feed forward neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "881014ce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "881014ce",
        "outputId": "6eab3f6d-7892-48b5-db60-c3c323f7c3d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-f0b3bf7b99f8>:24: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  (\"clf\", KerasClassifier(build_fn=lambda: create_ffnn_model(5000),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 4ms/step\n",
            "8/8 [==============================] - 0s 32ms/step\n",
            "8/8 [==============================] - 0s 3ms/step\n",
            "8/8 [==============================] - 0s 3ms/step\n",
            "8/8 [==============================] - 0s 5ms/step\n",
            "Feedforward Neural Network Macro F1 Score: 0.8316671626351718\n",
            "\n",
            "Classification Report for Feedforward Neural Network:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.91      0.77       320\n",
            "           1       0.81      0.61      0.69       320\n",
            "           2       0.92      0.83      0.87       320\n",
            "           3       0.99      0.98      0.99       320\n",
            "\n",
            "    accuracy                           0.83      1280\n",
            "   macro avg       0.85      0.83      0.83      1280\n",
            "weighted avg       0.85      0.83      0.83      1280\n",
            "\n",
            "Run time: 31.0361 seconds\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "#transformer to convert a sparse matrix (TFIDF) to a dense array because neural networks need dense arrays\n",
        "class DenseTransformer(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    def transform(self, X, y=None):\n",
        "        return X.todense()\n",
        "\n",
        "#feed forward neural network\n",
        "def create_ffnn_model(input_dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, activation='relu', input_dim=input_dim))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "nn_pipeline = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer(max_features=5000)),\n",
        "    (\"to_dense\", DenseTransformer()),\n",
        "    (\"clf\", KerasClassifier(build_fn=lambda: create_ffnn_model(5000),\n",
        "                              epochs=5, batch_size=32, verbose=0))\n",
        "])\n",
        "\n",
        "#generate predictions\n",
        "predicted_labels_nn = cross_val_predict(nn_pipeline, X_train, y_train, cv=skf, method=\"predict\")\n",
        "\n",
        "#print results\n",
        "f1_macro_nn = f1_score(y_train, predicted_labels_nn, average=\"macro\")\n",
        "print(\"Feedforward Neural Network Macro F1 Score:\", f1_macro_nn)\n",
        "print(\"\\nClassification Report for Feedforward Neural Network:\\n\", classification_report(y_train, predicted_labels_nn))\n",
        "print(\"Run time: {:.4f} seconds\".format(time.time() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Conclusion\n",
        "The baseline macro F1 score of 0.86 with Logistic Regression set the bar very high. Class 3 is the strongest class, while classes 0 and 1 are a bit behind with F1 scores of 0.79 and 0.77 respectively, but still well above our success metric of 0.6 for each class.\n",
        "\n",
        "The worst performing model by far was Multinomial Naive Bayes with a macro F1 score of 0.62. The inconsistency between precision and recall for different classes - class 0 has high recall but low precision while class 3 is the opposite - suggests that the naive assumption that each feature is independent of other features doesn't hold well here.\n",
        "\n",
        "The feedforward neural network is competitive with the others with a macro F1 of 0.85, but given that it shows no real advantage, and the dataset is relatively small with only 1,600 lines, the added complexity of a neural network isn't justified.\n",
        "\n",
        "XGBoost had the best macro score of 0.87 with a pretty balanced performance in each class. However, the runtime is significantly higher than the other models tested, coming in over 100 seconds while the others were all below 23 seconds.\n",
        "\n",
        "For the next phase I will take both Logistic Regression and XGBoost and experiment with some feature engineering to see if I can get improvements in the weaker classes (0 and 1)."
      ],
      "metadata": {
        "id": "2IvlT9KVoFlf"
      },
      "id": "2IvlT9KVoFlf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Feature Engineering\n",
        "\n",
        "####Generate Features\n",
        "Next we will define some custom tramsforms to generate different types of features.\n",
        "- Sentiment transformer which computes the polarity and subjectivity of a row using TextBlob\n",
        "- Named entity recognition (NER) transformer which counts the different entity types e.g. PERSON, ORG, DATE\n",
        "- Topic modelling using gensim's LDA"
      ],
      "metadata": {
        "id": "EaxubMwk9Gl7"
      },
      "id": "EaxubMwk9Gl7"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "682273cd",
      "metadata": {
        "id": "682273cd"
      },
      "outputs": [],
      "source": [
        "#sentiment analysis\n",
        "class SentimentTransformer(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    def transform(self, X, y=None):\n",
        "        #both polarity and subjectivity should be returned as features\n",
        "        features = np.array([\n",
        "            [TextBlob(text).sentiment.polarity, TextBlob(text).sentiment.subjectivity]\n",
        "            for text in X\n",
        "        ])\n",
        "        return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "4a8ee932",
      "metadata": {
        "id": "4a8ee932"
      },
      "outputs": [],
      "source": [
        "#named entity recognition\n",
        "class NERTransformer(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    def transform(self, X, y=None):\n",
        "        features = []\n",
        "        for text in X:\n",
        "            doc = nlp(text)\n",
        "            counts = {}\n",
        "            for ent in doc.ents:\n",
        "                counts[ent.label_] = counts.get(ent.label_, 0) + 1\n",
        "            #we want to return the count of the different entities\n",
        "            features.append(counts)\n",
        "        return features"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#topic modelling\n",
        "class TopicModelingTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, num_topics=5, passes=10):\n",
        "        self.num_topics = num_topics\n",
        "        self.passes = passes\n",
        "        self.dictionary = None\n",
        "        self.lda_model = None\n",
        "    def fit(self, X, y=None):\n",
        "        #text has already been cleaned so we can split on whitespace here to save time\n",
        "        tokenized = [text.split() for text in X]\n",
        "        self.dictionary = corpora.Dictionary(tokenized)\n",
        "        corpus = [self.dictionary.doc2bow(tokens) for tokens in tokenized]\n",
        "        self.lda_model = LdaModel(corpus, num_topics=self.num_topics, id2word=self.dictionary, passes=self.passes)\n",
        "        return self\n",
        "    def transform(self, X, y=None):\n",
        "        tokenized = [text.split() for text in X]\n",
        "        corpus = [self.dictionary.doc2bow(tokens) for tokens in tokenized]\n",
        "        features = []\n",
        "        for bow in corpus:\n",
        "            #get topic distribution\n",
        "            doc_topics = self.lda_model.get_document_topics(bow, minimum_probability=0)\n",
        "            #Form a fixed-length vector\n",
        "            doc_vector = [prob for (_, prob) in sorted(doc_topics, key=lambda x: x[0])]\n",
        "            features.append(doc_vector)\n",
        "        return np.array(features)"
      ],
      "metadata": {
        "id": "C2FpDtJk85YJ"
      },
      "id": "C2FpDtJk85YJ",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have the transformers ready, we will create a set of models with different combinations of the features for testing."
      ],
      "metadata": {
        "id": "pkvZLiZD_G_Q"
      },
      "id": "pkvZLiZD_G_Q"
    },
    {
      "cell_type": "code",
      "source": [
        "#this is our base transformer - just TF-IDF as we used in the initial model testing\n",
        "tfidf_transformer = (\"tfidf\", Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer(max_features=5000))\n",
        "]))\n",
        "\n",
        "#these are the other possible features that we can add\n",
        "feature_components = {\n",
        "    \"sentiment\": (\"sentiment\", SentimentTransformer()),\n",
        "    \"ner\": (\"ner\", Pipeline([\n",
        "        (\"ner\", NERTransformer()),\n",
        "        (\"vect\", DictVectorizer())\n",
        "    ])),\n",
        "    \"topic\": (\"topic\", TopicModelingTransformer(num_topics=5, passes=10))\n",
        "}\n",
        "additional_features = list(feature_components.keys())\n",
        "\n",
        "#this function is going to generate all subsets to make it easier to test different variations of features\n",
        "def powerset(iterable):\n",
        "    s = list(iterable)\n",
        "    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n",
        "\n",
        "\n",
        "#these are the two models we chose to test\n",
        "models = {\n",
        "    \"LogisticRegression\": LogisticRegression(max_iter=1000, random_state=999),\n",
        "    \"XGBoost\": XGBClassifier(eval_metric='mlogloss', random_state=999)\n",
        "}\n",
        "\n",
        "#again we'll use stratified k-fold for evaluation\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "32emQntt88o2"
      },
      "id": "32emQntt88o2",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "\n",
        "results = {}\n",
        "\n",
        "for model_name, clf in models.items():\n",
        "    results[model_name] = {}\n",
        "    print(f\"\\nEvaluating model: {model_name}\")\n",
        "    #iterate over all combos of additional features (including TF-IDF only)\n",
        "    for extra in powerset(additional_features):\n",
        "        #start with TF-IDF\n",
        "        components = [tfidf_transformer]\n",
        "        for feat in extra:\n",
        "            components.append(feature_components[feat])\n",
        "        #join the features horizontally\n",
        "        union = FeatureUnion(components)\n",
        "        #define pipeline\n",
        "        pipeline = Pipeline([\n",
        "            (\"features\", union),\n",
        "            (\"clf\", clf)\n",
        "        ])\n",
        "        #evaluate\n",
        "        predicted = cross_val_predict(pipeline, X_train, y_train, cv=skf, method=\"predict\")\n",
        "        f1_macro = f1_score(y_train, predicted, average=\"macro\")\n",
        "\n",
        "        #create a key for this combo\n",
        "        key = \"tfidf\"\n",
        "        if extra:\n",
        "            key += \"+\" + \"+\".join(extra)\n",
        "        else:\n",
        "            key += \"_only\"\n",
        "\n",
        "        results[model_name][key] = f1_macro\n",
        "        print(f\"Features: {key:30s} | Macro F1: {f1_macro:.4f}\")\n",
        "\n",
        "\n",
        "print(\"Run time: {:.4f} seconds\".format(time.time() - start_time))"
      ],
      "metadata": {
        "id": "9vZV56t_A-DF",
        "outputId": "a409e213-5566-47b5-c20d-17b42775e872",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        }
      },
      "id": "9vZV56t_A-DF",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating model: LogisticRegression\n",
            "Features: tfidf_only                     | Macro F1: 0.8678\n",
            "Features: tfidf+sentiment                | Macro F1: 0.8565\n",
            "Features: tfidf+ner                      | Macro F1: 0.8516\n",
            "Features: tfidf+topic                    | Macro F1: 0.8579\n",
            "Features: tfidf+sentiment+ner            | Macro F1: 0.8476\n",
            "Features: tfidf+sentiment+topic          | Macro F1: 0.8552\n",
            "Features: tfidf+ner+topic                | Macro F1: 0.8532\n",
            "Features: tfidf+sentiment+ner+topic      | Macro F1: 0.8563\n",
            "\n",
            "Evaluating model: XGBoost\n",
            "Features: tfidf_only                     | Macro F1: 0.8696\n",
            "Features: tfidf+sentiment                | Macro F1: 0.8750\n",
            "Features: tfidf+ner                      | Macro F1: 0.8783\n",
            "Features: tfidf+topic                    | Macro F1: 0.8563\n",
            "Features: tfidf+sentiment+ner            | Macro F1: 0.8799\n",
            "Features: tfidf+sentiment+topic          | Macro F1: 0.8597\n",
            "Features: tfidf+ner+topic                | Macro F1: 0.8802\n",
            "Features: tfidf+sentiment+ner+topic      | Macro F1: 0.8774\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Invalid format specifier '.4f]' for object of type 'float'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-9b571663023b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mbest_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nBest feature combination for {model_name}: {best_features} with Macro F1: {res[best_features]:.4f]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Run time: {:.4f} seconds\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid format specifier '.4f]' for object of type 'float'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Conclusion\n",
        "The best combination is the XGBoost model with TF-IDF, named entity recognition and topic modelling, with a macro F1 score of 0.88. This is the model that we will use for phase 2. Finally we will do a simple grid search to see if we can further tune the model.\n",
        "\n",
        "#### Build model"
      ],
      "metadata": {
        "id": "VPkAP_QWiqVM"
      },
      "id": "VPkAP_QWiqVM"
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "#create NER pipeline, use DictVectorizer to convert dicts to numeric features\n",
        "ner_pipeline = Pipeline([\n",
        "    (\"ner\", NERTransformer()),\n",
        "    (\"vect\", DictVectorizer())\n",
        "])\n",
        "\n",
        "#create topic modelling pipeline\n",
        "topic_pipeline = Pipeline([\n",
        "    (\"topic\", TopicModelingTransformer(num_topics=5, passes=10))\n",
        "])\n",
        "\n",
        "#combine features using FeatureUnion\n",
        "combined_features = FeatureUnion([\n",
        "    (\"tfidf\", TfidfVectorizer(max_features=5000)),\n",
        "    (\"ner\", ner_pipeline),\n",
        "    (\"topic\", topic_pipeline)\n",
        "])\n",
        "\n",
        "#build the final pipeline with XGBoost\n",
        "final_pipeline = Pipeline([\n",
        "    (\"features\", combined_features),\n",
        "    (\"clf\", XGBClassifier(eval_metric='mlogloss', random_state=999))\n",
        "])\n",
        "\n",
        "#split data into training and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=999)\n",
        "\n",
        "#fit model\n",
        "final_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate on the test set\n",
        "y_pred = final_pipeline.predict(X_test)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Macro F1 Score:\", f1_score(y_test, y_pred, average=\"macro\"))\n",
        "\n",
        "print(\"Run time: {:.4f} seconds\".format(time.time() - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wa8wLaPIio04",
        "outputId": "41dc11b0-5e9a-475e-9f79-e86ab5eff3f2"
      },
      "id": "wa8wLaPIio04",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.94      0.89        80\n",
            "           1       0.90      0.76      0.82        80\n",
            "           2       0.90      0.94      0.92        80\n",
            "           3       1.00      1.00      1.00        80\n",
            "\n",
            "    accuracy                           0.91       320\n",
            "   macro avg       0.91      0.91      0.91       320\n",
            "weighted avg       0.91      0.91      0.91       320\n",
            "\n",
            "Macro F1 Score: 0.908035921898593\n",
            "Run time: 236.7334 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save model\n",
        "joblib.dump(final_pipeline, \"final_pipeline.pkl\")\n",
        "print(\"Model saved to final_pipeline.pkl\")"
      ],
      "metadata": {
        "id": "KByxpv4LqS4Q",
        "outputId": "e5b6bfd0-c49f-4c32-9d70-92a8c82e69a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "KByxpv4LqS4Q",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to final_pipeline.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Grid Search"
      ],
      "metadata": {
        "id": "S7E7PqiTph9J"
      },
      "id": "S7E7PqiTph9J"
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "param_grid = {\n",
        "    \"clf__max_depth\": [3, 5, 7],\n",
        "    \"clf__learning_rate\": [0.01, 0.1, 0.2],\n",
        "    \"clf__n_estimators\": [50, 100, 200],\n",
        "    \"clf__subsample\": [0.8, 1.0]\n",
        "}\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=999)\n",
        "grid_search = GridSearchCV(estimator=final_pipeline, param_grid=param_grid, scoring=\"f1_macro\", cv=skf, n_jobs=-1, verbose=1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Macro F1 Score (CV):\", grid_search.best_score_)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred_test = best_model.predict(X_test)\n",
        "print(\"\\nTest Set Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_test))\n",
        "print(\"Test Set Macro F1 Score:\", f1_score(y_test, y_pred_test, average=\"macro\"))\n",
        "\n",
        "print(\"Run time: {:.4f} seconds\".format(time.time() - start_time))"
      ],
      "metadata": {
        "id": "Ngr1ONpxB95V"
      },
      "id": "Ngr1ONpxB95V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(best_model, \"phase_2_final_model_pipeline.pkl\")\n",
        "print(\"Model saved!\")"
      ],
      "metadata": {
        "id": "ba4clXqto5WF"
      },
      "id": "ba4clXqto5WF",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}