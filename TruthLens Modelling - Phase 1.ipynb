{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e0976e04",
      "metadata": {
        "id": "e0976e04"
      },
      "source": [
        "# TruthLens Modelling - Phase 1 : Binary Classification\n",
        "The aim of phase 1 is to classify text into real or fake. \"Fake\" content will move to phase 2 for multiclass classification, so essentially what we are trying to do with this stage is to filter out real news.\n",
        "\n",
        "The dataset used is the Misinformation & Fake News text dataset, which has already been cleaned and preprocessed (see \"TruthLens Data Cleaning\" notebook)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7c391f5d",
      "metadata": {
        "id": "7c391f5d"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "import time\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import csv\n",
        "import random\n",
        "import pickle\n",
        "pd.set_option('display.max_colwidth', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b39615dc",
      "metadata": {
        "id": "b39615dc"
      },
      "source": [
        "### Feature Extraction Using TF-IDF, n-grams and readability metrics\n",
        "In this section I will use a TfidfVectorizer to extract features from the training data. I will then combine these with the scaled readability metrics into one horizontally stacked feature matrix that I will use for modelling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9f55d404",
      "metadata": {
        "id": "9f55d404",
        "outputId": "2e1721c4-00a8-4ae2-ded8-23ad6a54a868",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     content  \\\n",
            "0  Of course, America s favorite criminal candidate says America shouldn t believe the infamous hacker who claims he accessed her unsecured server because he s a criminal. LOL if anyone can spot a criminal, it s Crooked Hillary The infamous Romanian hacker known as Guccifer, speaking exclusively with Fox News, claimed he easily and repeatedly breached former Secretary of State Hillary Clinton s personal email server in early 2013. For me, it was easy easy for me, for everybody, Marcel Lehel Lazar, who goes by the moniker Guccifer, told Fox News from a Virginia jail where he is being held.Guccifer s potential role in the Clinton email investigation was first reported by Fox News last month. The hacker subsequently claimed he was able to access the server and provided extensive details about how he did it and what he found over the course of a half-hour jailhouse interview and a series of recorded phone calls with Fox News.Fox News could not independently confirm Lazar s claims.In response to Lazar s claims, the Clinton campaign issued a statement Wednesday night saying, There is absolutely no basis to believe the claims made by this criminal from his prison cell. In addition to the fact he offers no proof to support his claims, his descriptions of Secretary Clinton s server are inaccurate. It is unfathomable that he would have gained access to her emails and not leaked them the way he did to his other victims. The former secretary of state s server held nearly 2,200 emails containing information now deemed classified, and another 22 at the Top Secret level. Via: FOX News   \n",
            "\n",
            "   label  word_count  sentence_count  flesch_reading_ease  \\\n",
            "0      1         270              11                46.61   \n",
            "\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             content_lemma  \\\n",
            "0  Of course , America s favorite criminal candidate say America shouldn t believe the infamous hacker who claim he access her unsecured server because he s a criminal . LOL if anyone can spot a criminal , it s Crooked Hillary The infamous Romanian hacker know a Guccifer , speak exclusively with Fox News , claim he easily and repeatedly breach former Secretary of State Hillary Clinton s personal email server in early 2013 . For me , it be easy easy for me , for everybody , Marcel Lehel Lazar , who go by the moniker Guccifer , tell Fox News from a Virginia jail where he be be held.Guccifer s potential role in the Clinton email investigation be first report by Fox News last month . The hacker subsequently claim he be able to access the server and provide extensive detail about how he do it and what he find over the course of a half-hour jailhouse interview and a series of recorded phone call with Fox News.Fox News could not independently confirm Lazar s claims.In response to Lazar s claim , the Clinton campaign issue a statement Wednesday night say , There be absolutely no basis to believe the claim make by this criminal from his prison cell . In addition to the fact he offer no proof to support his claim , his description of Secretary Clinton s server be inaccurate . It be unfathomable that he would have gain access to her email and not leak them the way he do to his other victim . The former secretary of state s server hold nearly 2,200 email contain information now deem classify , and another 22 at the Top Secret level . Via : FOX News   \n",
            "\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            content_lemma_nostop  \n",
            "0  course america favorite criminal candidate say america believe infamous hacker claim access unsecured server criminal lol anyone spot criminal crooked hillary infamous romanian hacker know guccifer speak exclusively fox news claim easily repeatedly breach former secretary state hillary clinton personal email server early 2013 easy easy everybody marcel lehel lazar go moniker guccifer tell fox news virginia jail heldguccifer potential role clinton email investigation first report fox news last month hacker subsequently claim able access server provide extensive detail find course halfhour jailhouse interview series recorded phone call fox newsfox news could independently confirm lazar claimsin response lazar claim clinton campaign issue statement wednesday night say absolutely basis believe claim make criminal prison cell addition fact offer proof support claim description secretary clinton server inaccurate unfathomable would gain access email leak way victim former secretary state server hold nearly 2200 email contain information deem classify another 22 top secret level via fox news  \n"
          ]
        }
      ],
      "source": [
        "#load data\n",
        "df = pd.read_csv('Data/phase1_final_clean.csv')\n",
        "df = df.reset_index(drop=True)\n",
        "print(df.head(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "640da603",
      "metadata": {
        "id": "640da603",
        "outputId": "80543b61-4c7c-4a90-c77b-678d3ac293cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature extraction: 256.7663 seconds\n"
          ]
        }
      ],
      "source": [
        "#TF-IDF feature extraction with n-grams\n",
        "start_time = time.time()\n",
        "#replace NaN values with an empty string to resolve NaN ValueError\n",
        "df['content_lemma_nostop'] = df['content_lemma_nostop'].fillna('')\n",
        "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 3))\n",
        "X_tfidf = vectorizer.fit_transform(df['content_lemma_nostop'])\n",
        "#get pre-calculated readability features\n",
        "readability_features = df[['word_count', 'sentence_count', 'flesch_reading_ease']].values\n",
        "#standardise readability features\n",
        "scaler = StandardScaler()\n",
        "readability_scaled = scaler.fit_transform(readability_features)\n",
        "#convert to a sparse matrix\n",
        "readability_sparse = csr_matrix(readability_scaled)\n",
        "#combine TF-IDF features with the readability metrics\n",
        "X_combined = hstack([X_tfidf, readability_sparse])\n",
        "\n",
        "y = df['label']\n",
        "print(\"Feature extraction: {:.4f} seconds\".format(time.time() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0949d9b",
      "metadata": {
        "id": "c0949d9b"
      },
      "source": [
        "### Split dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "daf94d1a",
      "metadata": {
        "id": "daf94d1a"
      },
      "outputs": [],
      "source": [
        "#retain the indices as we need these for looking up explanations later\n",
        "train_indices, test_indices = train_test_split(df.index, test_size=0.2, random_state=999)\n",
        "#split X and y using the train/test indices\n",
        "X_train = X_combined[train_indices]\n",
        "X_test = X_combined[test_indices]\n",
        "y_train = y.iloc[train_indices]\n",
        "y_test = y.iloc[test_indices]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d24cd01e",
      "metadata": {
        "id": "d24cd01e"
      },
      "source": [
        "### Phase 1 Modelling\n",
        "I will test three different models on the data to see which is best. The models to be tested are:\n",
        "- Logistic Regression\n",
        "- Random Forest\n",
        "- Support Vector Machine (SVM)\n",
        "\n",
        "#### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a99a164",
      "metadata": {
        "id": "4a99a164",
        "outputId": "6df8001c-48aa-44ad-ffa5-479e74e2cf50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fit Logistic Regression model: 6.0120 seconds\n",
            "Accuracy: 0.942295457437333\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.93      0.93      6931\n",
            "           1       0.94      0.95      0.95      8787\n",
            "\n",
            "    accuracy                           0.94     15718\n",
            "   macro avg       0.94      0.94      0.94     15718\n",
            "weighted avg       0.94      0.94      0.94     15718\n",
            "\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Fit Logistic Regression model: {:.4f} seconds\".format(time.time() - start_time))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e8795bc",
      "metadata": {
        "id": "9e8795bc"
      },
      "source": [
        "#### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cd2b147",
      "metadata": {
        "id": "5cd2b147",
        "outputId": "05db7a93-4939-4c8d-fa82-a63559216a09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fit Random Forest model: 347.0968 seconds\n",
            "Random Forest Accuracy: 0.9523476269245451\n",
            "Random Forest Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.94      0.95      6931\n",
            "           1       0.95      0.96      0.96      8787\n",
            "\n",
            "    accuracy                           0.95     15718\n",
            "   macro avg       0.95      0.95      0.95     15718\n",
            "weighted avg       0.95      0.95      0.95     15718\n",
            "\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "rf_model = RandomForestClassifier()\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_pred = rf_model.predict(X_test)\n",
        "print(\"Fit Random Forest model: {:.4f} seconds\".format(time.time() - start_time))\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, rf_pred))\n",
        "print(\"Random Forest Classification Report:\\n\", classification_report(y_test, rf_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d1a7b5e",
      "metadata": {
        "id": "5d1a7b5e"
      },
      "source": [
        "#### Support Vector Machine (SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b292177",
      "metadata": {
        "id": "9b292177",
        "outputId": "69c05bac-ec3d-4774-eecb-0658a77748dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fit SVM model: 4252.7811 seconds\n",
            "SVM Accuracy: 0.9504389871484922\n",
            "SVM Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.93      0.94      6931\n",
            "           1       0.95      0.96      0.96      8787\n",
            "\n",
            "    accuracy                           0.95     15718\n",
            "   macro avg       0.95      0.95      0.95     15718\n",
            "weighted avg       0.95      0.95      0.95     15718\n",
            "\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "svm_model = SVC()\n",
        "svm_model.fit(X_train, y_train)\n",
        "svm_pred = svm_model.predict(X_test)\n",
        "print(\"Fit SVM model: {:.4f} seconds\".format(time.time() - start_time))\n",
        "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_pred))\n",
        "print(\"SVM Classification Report:\\n\", classification_report(y_test, svm_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d7a7637",
      "metadata": {
        "id": "6d7a7637"
      },
      "source": [
        "#### Conclusion\n",
        "For phase 1 to be successful according to our success metrics, we want an accuracy of at least 90%. All three algorithms tested have performed better than that.\n",
        "\n",
        "Random Forest and SVM both had an accuracy of 0.95 which is impressive. Logistic regression was slightly lower with an accuracy of 0.94. However, when computational efficiency is taken into account, Logistic regression is the preferred model. It took just over 6 seconds to fit the Logistic regression model to our data, compared to 347 seconds (almost 6 minutes) for random forest, and a whooping 4252 seconds (just under 71 minutes) for SVM.\n",
        "\n",
        "Next we will test what column works best - content, content_lemma (which is lemmatised) or content_lemma_nostop (which is lemmatised and additionally has stopwords and punctuation removed.)\n",
        "\n",
        "### Column selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfff84cc",
      "metadata": {
        "id": "cfff84cc"
      },
      "outputs": [],
      "source": [
        "def evaluate_text_representation(text_column, df):\n",
        "    print(\"Evaluating model on \",text_column)\n",
        "    start_time = time.time()\n",
        "    #replace NaN values with an empty string to resolve NaN ValueError\n",
        "    df[text_column] = df[text_column].fillna('')\n",
        "\n",
        "    #get TF-IDF features for the chosen text column\n",
        "    vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 3))\n",
        "    X_tfidf = vectorizer.fit_transform(df[text_column])\n",
        "\n",
        "    #get pre-calculated readability features\n",
        "    readability_features = df[['word_count', 'sentence_count', 'flesch_reading_ease']].values\n",
        "    scaler = StandardScaler()\n",
        "    #standardise readability features\n",
        "    readability_scaled = scaler.fit_transform(readability_features)\n",
        "    #convert to a sparse matrix\n",
        "    readability_sparse = csr_matrix(readability_scaled)\n",
        "\n",
        "    #combine TF-IDF features with the readability metrics\n",
        "    X_combined = hstack([X_tfidf, readability_sparse])\n",
        "\n",
        "    y = df['label']\n",
        "\n",
        "    #split the data into training and testing sets using the dataframe index\n",
        "    train_indices, test_indices = train_test_split(df.index, test_size=0.2, random_state=999)\n",
        "    X_train = X_combined[train_indices]\n",
        "    X_test = X_combined[test_indices]\n",
        "    y_train = y.iloc[train_indices]\n",
        "    y_test = y.iloc[test_indices]\n",
        "\n",
        "    #train a simple Logistic Regression model\n",
        "    model = LogisticRegression(max_iter=1000)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    elapsed_time = time.time() - start_time\n",
        "\n",
        "    # Evaluate and print the results\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    print(f\"Results for '{text_column}':\")\n",
        "    print(\"Time elapsed: {:.4f} seconds\".format(elapsed_time))\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Classification Report:\\n\", report)\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    return accuracy, model, vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a521e8e5",
      "metadata": {
        "id": "a521e8e5",
        "outputId": "928e51d5-d54b-438f-e1a6-46af1823d5f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model on  content\n",
            "Results for 'content':\n",
            "Time elapsed: 399.0861 seconds\n",
            "Accuracy: 0.9401323323578064\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.92      0.93      6931\n",
            "           1       0.94      0.95      0.95      8787\n",
            "\n",
            "    accuracy                           0.94     15718\n",
            "   macro avg       0.94      0.94      0.94     15718\n",
            "weighted avg       0.94      0.94      0.94     15718\n",
            "\n",
            "--------------------------------------------------\n",
            "Evaluating model on  content_lemma\n",
            "Results for 'content_lemma':\n",
            "Time elapsed: 355.7318 seconds\n",
            "Accuracy: 0.9481486194172286\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.93      0.94      6931\n",
            "           1       0.95      0.96      0.95      8787\n",
            "\n",
            "    accuracy                           0.95     15718\n",
            "   macro avg       0.95      0.95      0.95     15718\n",
            "weighted avg       0.95      0.95      0.95     15718\n",
            "\n",
            "--------------------------------------------------\n",
            "Evaluating model on  content_lemma_nostop\n",
            "Results for 'content_lemma_nostop':\n",
            "Time elapsed: 299.1153 seconds\n",
            "Accuracy: 0.942295457437333\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.93      0.93      6931\n",
            "           1       0.94      0.95      0.95      8787\n",
            "\n",
            "    accuracy                           0.94     15718\n",
            "   macro avg       0.94      0.94      0.94     15718\n",
            "weighted avg       0.94      0.94      0.94     15718\n",
            "\n",
            "--------------------------------------------------\n",
            "Summary of accuracies:\n",
            "content: 0.9401\n",
            "content_lemma: 0.9481\n",
            "content_lemma_nostop: 0.9423\n",
            "\n",
            "Best performing column: content_lemma with accuracy: 0.9481\n"
          ]
        }
      ],
      "source": [
        "#columns to test\n",
        "text_columns = ['content', 'content_lemma', 'content_lemma_nostop']\n",
        "results = {}\n",
        "\n",
        "#run the evaluation for each column\n",
        "for col in text_columns:\n",
        "    acc, model, vectorizer = evaluate_text_representation(col, df)\n",
        "    results[col] = {'accuracy': acc, 'model': model, 'vectorizer': vectorizer}\n",
        "\n",
        "#identify the best performing model based on accuracy\n",
        "best_column = max(results, key=lambda x: results[x]['accuracy'])\n",
        "best_result = results[best_column]\n",
        "\n",
        "#print a summary of the accuracies\n",
        "print(\"Summary of accuracies:\")\n",
        "for col, result in results.items():\n",
        "    print(f\"{col}: {result['accuracy']:.4f}\")\n",
        "\n",
        "print(f\"\\nBest performing column: {best_column} with accuracy: {best_result['accuracy']:.4f}\")\n",
        "\n",
        "#set the best model\n",
        "best_model = best_result['model']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1adbc21",
      "metadata": {
        "id": "a1adbc21"
      },
      "source": [
        "#### Results\n",
        "As we can see from the output above, the classifier performed best on the lemmatised column, with an accuracy of 0.9481.\n",
        "\n",
        "Next we will use some tuning to try and increase the accuracy of our logistic regression model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c636d5dc",
      "metadata": {
        "id": "c636d5dc"
      },
      "source": [
        "### Tweak model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This code is repeated from the top of the file - look into making this a fucntion to reduce repetition\n",
        "#Also I've just calculated most of this in the previous function - see if I can maybe get it from there instead of recalculating\n",
        "start_time = time.time()\n",
        "#replace NaN values with an empty string to resolve NaN ValueError\n",
        "df['content_lemma'] = df['content_lemma'].fillna('')\n",
        "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 3))\n",
        "X_tfidf = vectorizer.fit_transform(df['content_lemma'])\n",
        "#get pre-calculated readability features\n",
        "readability_features = df[['word_count', 'sentence_count', 'flesch_reading_ease']].values\n",
        "#standardise readability features\n",
        "scaler = StandardScaler()\n",
        "readability_scaled = scaler.fit_transform(readability_features)\n",
        "#convert to a sparse matrix\n",
        "readability_sparse = csr_matrix(readability_scaled)\n",
        "#combine TF-IDF features with the readability metrics\n",
        "X_combined = hstack([X_tfidf, readability_sparse])\n",
        "\n",
        "y = df['label']\n",
        "print(\"Feature extraction: {:.4f} seconds\".format(time.time() - start_time))\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "SENZi1Za2rj_",
        "outputId": "7d553fcb-c7fc-472a-d4a3-26eccd7bbe20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "SENZi1Za2rj_",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature extraction: 301.6178 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Qmz49-xf3P0F"
      },
      "outputs": [],
      "source": [
        "#retain the indices as we need these for looking up explanations later\n",
        "train_indices, test_indices = train_test_split(df.index, test_size=0.2, random_state=999)\n",
        "#split X and y using the train/test indices\n",
        "X_train = X_combined[train_indices]\n",
        "X_test = X_combined[test_indices]\n",
        "y_train = y.iloc[train_indices]\n",
        "y_test = y.iloc[test_indices]"
      ],
      "id": "Qmz49-xf3P0F"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "bd569a08",
      "metadata": {
        "id": "bd569a08",
        "outputId": "85a65f9e-18cf-4d24-f83a-b7c6d7d39139",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Best cross-validation score: 0.954254805167687\n",
            "Grid Search: 15976.0700 seconds\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "#we're going to test for the best combo of regularisation type (l1 or l2), C values, and solvers\n",
        "param_grid = [\n",
        "    {\n",
        "        #l1 regularisation\n",
        "        'penalty': ['l1'],\n",
        "        'C': [0.1, 1, 10],\n",
        "        'solver': ['liblinear', 'saga']\n",
        "    },\n",
        "    {\n",
        "        #l2 regularization\n",
        "        'penalty': ['l2'],\n",
        "        'C': [0.1, 1, 10],\n",
        "        'solver': ['saga', 'sag']\n",
        "    }\n",
        "]\n",
        "\n",
        "#set up the grid search\n",
        "grid = GridSearchCV(LogisticRegression(max_iter=2000), param_grid, cv=3, n_jobs = -1)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "#print the best parameters and best score, and the time it took\n",
        "print(\"Best parameters:\", grid.best_params_)\n",
        "print(\"Best cross-validation score:\", grid.best_score_)\n",
        "print(\"Grid Search: {:.4f} seconds\".format(time.time() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2412b71f",
      "metadata": {
        "id": "2412b71f"
      },
      "source": [
        "#### Tuning Results\n",
        "As we can see from the above results XXXX\n",
        "\n",
        "### Create and save final Phase 1 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc051ec0",
      "metadata": {
        "id": "fc051ec0"
      },
      "outputs": [],
      "source": [
        "#instantiate the final model with the best hyperparameters as found by the grid search\n",
        "final_model = LogisticRegression(C=10, penalty='l2', solver='sag', max_iter=2000)\n",
        "\n",
        "#fit the model\n",
        "final_model.fit(X_train, y_train)\n",
        "\n",
        "#evaluate on the test set\n",
        "final_predictions = final_model.predict(X_test)\n",
        "print(\"Final Model Accuracy:\", accuracy_score(y_test, final_predictions))\n",
        "print(\"Final Model Classification Report:\\n\", classification_report(y_test, final_predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cac9bc7f",
      "metadata": {
        "id": "cac9bc7f"
      },
      "outputs": [],
      "source": [
        "#save our model\n",
        "with open('final_model.pkl', 'wb') as file:\n",
        "    pickle.dump(final_model, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9198bed",
      "metadata": {
        "id": "d9198bed"
      },
      "source": [
        "### Validate model\n",
        "Extra data from https://www.kaggle.com/datasets/stevenpeutz/misinformation-fake-news-text-dataset-79k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b63a12c4",
      "metadata": {
        "id": "b63a12c4"
      },
      "outputs": [],
      "source": [
        "#load in validation dataset\n",
        "external_df = pd.read_csv('Data/extra_data_final_clean.csv')\n",
        "external_df = external_df.dropna(subset=['content_lemma_nostop']).reset_index(drop=True)\n",
        "external_text = external_df['content_lemma_nostop']\n",
        "external_labels = external_df['label']\n",
        "\n",
        "# Transform the external data using the already fitted vectorizer (or pipeline)\n",
        "X_external = vectorizer.transform(external_text)\n",
        "\n",
        "# Predict using the trained model\n",
        "external_predictions_lr = final_model.predict(X_external)\n",
        "\n",
        "# Evaluate the performance on the external dataset\n",
        "print(\"External Dataset Classification Report:\\n\", classification_report(external_labels, external_predictions_lr))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f23fe07b",
      "metadata": {
        "id": "f23fe07b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}